{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksnugroho/feel-in/blob/main/twitter-scraper/01_main_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G8k-JXgwwuYe",
      "metadata": {
        "id": "G8k-JXgwwuYe"
      },
      "source": [
        "# **Main Twitter Scraper**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PCl23Etkt09i",
      "metadata": {
        "id": "PCl23Etkt09i"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PuD0Zueot3Ex",
      "metadata": {
        "id": "PuD0Zueot3Ex"
      },
      "outputs": [],
      "source": [
        "# Path to google drive folder\n",
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ekIroTB3t4vA",
      "metadata": {
        "id": "ekIroTB3t4vA"
      },
      "outputs": [],
      "source": [
        "# https://pypi.org/project/snscrape/0.2.0/\n",
        "!pip install -q snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb29263-aacb-4bdf-b5ff-d96bef3f99a0",
      "metadata": {
        "id": "dfb29263-aacb-4bdf-b5ff-d96bef3f99a0"
      },
      "outputs": [],
      "source": [
        "# function to get the tweets from a user\n",
        "def tweet_scraper(keywords, start_date, end_date, num_of_tweets=500, lang='id'):\n",
        "    \"\"\"\n",
        "    Paremters:\n",
        "    ----------------\n",
        "    keywords: str\n",
        "    start_date: str (format yyyy-mm-dd)\n",
        "    end_date: str (format yyyy-mm-dd)\n",
        "    num_of_tweets: int (default 500)\n",
        "    lang: str (default 'id')\n",
        "\n",
        "    Return:\n",
        "    ----------------\n",
        "    df: dataframe\n",
        "\n",
        "    Example:\n",
        "    ----------------\n",
        "    tweet_scrapper('marah', '2019-01-01', '2021-11-01', num_of_tweets=500, lang='id')\n",
        "    \"\"\"\n",
        "\n",
        "    import pandas as pd\n",
        "    import snscrape.modules.twitter as sntwitter\n",
        "    from timeit import default_timer as timer\n",
        "\n",
        "    start = timer()\n",
        "\n",
        "    # creating list to append tweet data\n",
        "    tweets_list = []\n",
        "\n",
        "    # using TwitterSearchScraper to scrape data and append tweets to list\n",
        "    criteria = f'{keywords} since:{start_date} until:{end_date} lang:{lang} exclude:retweets exclude:replies'\n",
        "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(criteria).get_items()):\n",
        "        if i > num_of_tweets:\n",
        "            break\n",
        "        tweets_list.append([tweet.date, tweet.content])\n",
        "\n",
        "    # creating a dataframe from the tweets list above\n",
        "    df = pd.DataFrame(tweets_list, columns=['datetime', 'tweet'])\n",
        "    df = df.dropna()            # dropping rows with NaN values\n",
        "    df = df.drop_duplicates()   # dropping duplicates\n",
        "\n",
        "    end = timer()\n",
        "    print('Time taken:', end - start, 'seconds')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d23f4a-68c5-4c83-94b3-7c44e6577714",
      "metadata": {
        "id": "82d23f4a-68c5-4c83-94b3-7c44e6577714"
      },
      "outputs": [],
      "source": [
        "emotion_keywords = {\n",
        "    'anger'     : ['kesal', 'murka', 'benci', 'marah', 'tersinggung'],\n",
        "    'disgust'   : ['muak', 'risih', 'penat', 'jijik', 'enek'],\n",
        "    'fear'      : ['takut', 'ngeri', 'cemas', 'gugup', 'tersiksa'],\n",
        "    'joy'       : ['senang', 'bangga', 'bahagia', 'puas', 'riang'],\n",
        "    'sadness'   : ['kecewa', 'sedih', 'berduka', 'sengsara', 'kesepian'],\n",
        "    'surprise'  : ['heran', 'terkejut', 'terpesona', 'tertipu', 'kaget']\n",
        "}\n",
        "\n",
        "start_date  = '2020-01-01'\n",
        "end_date    = '2020-12-31'\n",
        "folder_path = 'twitter-scraper/data-raw'\n",
        "num_of_tweets = 100000 \n",
        "\n",
        "result = {}  # creating a dictionary to store data\n",
        "\n",
        "for emotion, keywords in emotion_keywords.items():\n",
        "    for key in keywords:\n",
        "        result[key] = tweet_scraper(key, start_date=start_date, end_date=end_date, num_of_tweets=num_of_tweets)\n",
        "        result[key].to_csv(f'{folder_path}/{emotion}/{key}-{start_date}-{end_date}.csv')\n",
        "\n",
        "print('Done!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "01-main-scraper.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
