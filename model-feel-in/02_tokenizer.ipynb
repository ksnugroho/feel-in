{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1f2346-6473-4bce-a2be-cc82a61a73ee",
   "metadata": {},
   "source": [
    "# Training RoBERTa Tokenizer\n",
    "\n",
    "Byte-Pair Encoding tokenization https://youtu.be/HEikzVL-lZU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5a387-efd0-4797-8786-02bdf6975c7a",
   "metadata": {},
   "source": [
    "# 01 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59943713-da05-47f0-81ac-058082714edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset path\n",
    "import pickle\n",
    "\n",
    "with open('data/all_dataset_path', 'rb') as fp:\n",
    "    all_dataset_path = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef37dff7-b165-4471-8ab6-1070de775666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44aa398a-a4ac-4826-beff-f8ad0eb0445b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/id_oscar/text_543.txt',\n",
       " 'data/id_oscar/text_155.txt',\n",
       " 'data/id_oscar/text_528.txt',\n",
       " 'data/id_oscar/text_582.txt',\n",
       " 'data/id_oscar/text_983.txt',\n",
       " 'data/id_oscar/text_919.txt',\n",
       " 'data/id_oscar/text_729.txt',\n",
       " 'data/id_oscar/text_857.txt',\n",
       " 'data/id_oscar/text_246.txt',\n",
       " 'data/id_oscar/text_222.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see merge path\n",
    "all_dataset_path[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca7a24-0dc6-4320-9fc2-e27f1ca77b74",
   "metadata": {},
   "source": [
    "# 02 Build a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296208c5-2375-4c79-a575-5e13f12edfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 5h 48min 37s, sys: 24min 56s, total: 6h 13min 33s\n",
      "Wall time: 24min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "# https://huggingface.co/docs/tokenizers/api/trainers#tokenizers.trainers.BpeTrainer\n",
    "\n",
    "# RoBERTa's default vocabulary size is 50_265 (compare this to BERT's uncased 30_522)\n",
    "tokenizer.train(\n",
    "    files=all_dataset_path, \n",
    "    vocab_size=50_265,\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>']\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5162d-1451-400a-b0c6-97c7ebce2845",
   "metadata": {},
   "source": [
    "# 03 Save Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa978d9b-4f4e-4da1-b8bc-a1d690e6a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feel-in/vocab.json', 'feel-in/merges.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('feel-in') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280d840-6853-43cd-bf04-c3547b1f70a8",
   "metadata": {},
   "source": [
    "# 04 Load Tokenizer (Example Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8437c552-54f0-49ca-882c-b28ce92ff158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "vocab_file_dir = 'feel-in'\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(vocab_file_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220c076c-cae7-4322-8356-800ee7e4b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Hidup tidak selamanya berjalan dengan mulus'\n",
    "token = roberta_tokenizer.tokenize(sentence)\n",
    "enc = roberta_tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8321e581-3cbf-4664-8245-8c932be283bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'idup', 'Ġtidak', 'Ġselamanya', 'Ġberjalan', 'Ġdengan', 'Ġmulus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ebe623-3e75-4b0b-987e-635430a0964b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 44, 720, 365, 7601, 1675, 326, 8924, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:indo-emo-bert] *",
   "language": "python",
   "name": "conda-env-indo-emo-bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
