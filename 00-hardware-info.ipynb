{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f8bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] There are 1 GPU(s) available.\n",
      "[INFO] Device name: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# Check avalaible GPU via PyTorch\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'[INFO] There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('[INFO] Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('[INFO] No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0effe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Your runtime has 269.2 gigabytes of available RAM\n"
     ]
    }
   ],
   "source": [
    "# Check avalaible RAM\n",
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('[INFO] Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132d5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CPU Core: 104\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_core = multiprocessing.cpu_count()\n",
    "print(f'[INFO] CPU Core: {cpu_core}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b6f66b-e941-4512-aa16-549bc2f64cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 22:56:02.985826: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-22 22:56:02.987077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-05-22 22:56:02.987201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-22 22:56:02.987282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-22 22:56:02.987297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-05-22 22:56:02.987312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-22 22:56:02.987328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-22 22:56:02.987344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-22 22:56:02.987357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-22 22:56:02.987372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-22 22:56:02.987935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-22 22:56:07.477274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-22 22:56:07.477378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-22 22:56:07.477391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-22 22:56:07.479386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 42638 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# Check avalaible GPU via TensorFlow\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    device = device_lib.list_local_devices()\n",
    "    return [x.name for x in device]\n",
    "\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4b303b-a2a6-4e69-a62c-b70c8ee78394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 21 03:05:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:AF:00.0 Off |                  Off |\n",
      "| 36%   61C    P2   104W / 260W |  12463MiB / 49152MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2668      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     13155      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   2404644      C   ...dinu/.venv/phd/bin/python    12145MiB |\n",
      "|    0   N/A  N/A   3112802      C   ...indo-emo-bert/bin/python3      305MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6abd0a6a-99d8-4662-a57a-7ea0a60ae222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Product Name                          : Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -q -i 0 | grep \"Product Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63d7d4-9001-47ec-b089-b80041446ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
