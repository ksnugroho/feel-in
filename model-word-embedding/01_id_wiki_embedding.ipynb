{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksnugroho/feel-in/blob/main/model-word-embedding/01_id_wiki_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dd10fa7-2c38-435e-b6d2-380d9c114527",
      "metadata": {
        "id": "5dd10fa7-2c38-435e-b6d2-380d9c114527"
      },
      "source": [
        "# **Create Word Embedding (Word2Vec & FastText) from ID Wikipedia Dump**\n",
        "\n",
        "**Thesis: Emotion Detection in Indonesian Text**\n",
        "\n",
        "Kuncahyo Setyo Nugroho<br>\n",
        "Supervisor:\n",
        "1. Dr. Eng. Fitra A. Bachtiar, S.T., M.Eng.\n",
        "2. Prof. Ir. Wayan Firdaus Mahmudy, S.Si., M.T., Ph.D.\n",
        "\n",
        "Faculty of Computer Science, Brawijaya University, Indonesia &copy; 2021-2022"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c6765ab-c865-4246-b63f-5e43da2067b3",
      "metadata": {
        "id": "8c6765ab-c865-4246-b63f-5e43da2067b3"
      },
      "source": [
        "# 01 Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KZdHZyAkabz",
        "outputId": "4a3d2886-f4ac-479d-8c0d-e6aa8722625f"
      },
      "id": "7KZdHZyAkabz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to google drive folder\n",
        "%cd /content/drive/MyDrive/Code/tesis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btgqSGI4kbuS",
        "outputId": "cbed7a17-20e8-4597-f1d2-4ef1a5d46fa1"
      },
      "id": "btgqSGI4kbuS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Code/tesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8bdc2e4-c0f4-4b9b-8a02-e16855ac22b1",
      "metadata": {
        "id": "a8bdc2e4-c0f4-4b9b-8a02-e16855ac22b1"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import multiprocessing\n",
        "import gensim\n",
        "from gensim.corpora import WikiCorpus\n",
        "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84cd822e-ddbd-458b-b58c-33a6867496a6",
      "metadata": {
        "id": "84cd822e-ddbd-458b-b58c-33a6867496a6",
        "outputId": "780b8644-650b-4fbf-8d4e-d685928d32ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "gensim.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56caacf2-83d8-4f99-879e-23bad841715c",
      "metadata": {
        "id": "56caacf2-83d8-4f99-879e-23bad841715c"
      },
      "source": [
        "# 02 Load & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7da1c8d-ea0a-4c85-8e95-ccddd35a9c58",
      "metadata": {
        "id": "e7da1c8d-ea0a-4c85-8e95-ccddd35a9c58",
        "outputId": "bb923b8b-6f5a-43da-b5b9-2be95592e58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 articles processed\n",
            "20000 articles processed\n",
            "30000 articles processed\n",
            "40000 articles processed\n",
            "50000 articles processed\n",
            "60000 articles processed\n",
            "70000 articles processed\n",
            "80000 articles processed\n",
            "90000 articles processed\n",
            "100000 articles processed\n",
            "110000 articles processed\n",
            "120000 articles processed\n",
            "130000 articles processed\n",
            "140000 articles processed\n",
            "150000 articles processed\n",
            "160000 articles processed\n",
            "170000 articles processed\n",
            "180000 articles processed\n",
            "190000 articles processed\n",
            "200000 articles processed\n",
            "210000 articles processed\n",
            "220000 articles processed\n",
            "230000 articles processed\n",
            "240000 articles processed\n",
            "250000 articles processed\n",
            "260000 articles processed\n",
            "270000 articles processed\n",
            "280000 articles processed\n",
            "290000 articles processed\n",
            "300000 articles processed\n",
            "310000 articles processed\n",
            "320000 articles processed\n",
            "330000 articles processed\n",
            "340000 articles processed\n",
            "350000 articles processed\n",
            "360000 articles processed\n",
            "370000 articles processed\n",
            "380000 articles processed\n",
            "390000 articles processed\n",
            "400000 articles processed\n",
            "410000 articles processed\n",
            "420000 articles processed\n",
            "430000 articles processed\n",
            "440000 articles processed\n",
            "450000 articles processed\n",
            "460000 articles processed\n",
            "total: 462462 articles\n",
            "Elapsed time: 0:17:46.152890\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "file_path = 'data/id-wiki-dump'\n",
        "\n",
        "id_wiki = WikiCorpus(\n",
        "    f'{file_path}/idwiki-latest-pages-articles.xml.bz2',\n",
        "    dictionary={}, \n",
        "    processes=multiprocessing.cpu_count()-1, \n",
        "    lower=True\n",
        "  )\n",
        "\n",
        "article_count = 0\n",
        "with io.open(f'{file_path}/id-wiki_dump_lower.txt', 'w', encoding='utf-8') as wiki_txt:\n",
        "    for text in id_wiki.get_texts():\n",
        "        wiki_txt.write(' '.join(text) + '\\n')\n",
        "        article_count += 1\n",
        "        \n",
        "        if article_count % 10000 == 0:\n",
        "            print('{} articles processed'.format(article_count))\n",
        "            \n",
        "finish_time = time.time()\n",
        "\n",
        "print('total: {} articles'.format(article_count))\n",
        "print('Elapsed time: {}'.format(timedelta(seconds=finish_time-start_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12a5cb6b-d7b0-44ae-be59-418e382d71b0",
      "metadata": {
        "id": "12a5cb6b-d7b0-44ae-be59-418e382d71b0"
      },
      "outputs": [],
      "source": [
        "sentences = gensim.models.word2vec.LineSentence(f'{file_path}/id-wiki_dump_lower.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e27a22a-e9e6-4813-808d-b3c46f0fb86a",
      "metadata": {
        "id": "7e27a22a-e9e6-4813-808d-b3c46f0fb86a"
      },
      "source": [
        "# 03 Define Training Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef5fcc6-d8d5-4a31-8c52-7c609602f7b3",
      "metadata": {
        "id": "aef5fcc6-d8d5-4a31-8c52-7c609602f7b3",
        "outputId": "b47db799-ac01-426b-b387-75b94b827bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU CORES: 4\n"
          ]
        }
      ],
      "source": [
        "# https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
        "\n",
        "CPU_CORES = multiprocessing.cpu_count()  # Jumlah CPU core pada komputer\n",
        "EMBEDDING_SIZE = 300                     # Dimensi word vektors\n",
        "WINDOW_SIZE = 5                          # Window size. Jarak maksimum antara kata saat ini dan yang diprediksi dalam sebuah kalimat\n",
        "MIN_WORD = 5                             # Model akan mengabaikan semua kata dengan frekuensi total lebih rendah dari ini (opsional)\n",
        "EPOCH = 10                               # Jumlah iterasi (epoch)\n",
        "SG = 1                                   # Strategi algoritma pelatihan: 1 untuk skip-gram, 0 untuk CBOW\n",
        "NEGATIVE = 5                             # Negative sampling. Jika 0, negative sampling tidak digunakan\n",
        "HS = 0                                   # Hierarchical softmax. Jika 1, hierarchical softmax difunakan\n",
        "SEED = 69                                # Number generator\n",
        "\n",
        "print('CPU CORES:', CPU_CORES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66211dcc-c114-485c-abd4-1a1b58dce1a0",
      "metadata": {
        "id": "66211dcc-c114-485c-abd4-1a1b58dce1a0"
      },
      "outputs": [],
      "source": [
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(\"Epoch #{} start\".format(self.epoch))\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        print(\"Epoch #{} end\".format(self.epoch))\n",
        "        self.epoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original source: https://github.com/HichemMaiza/Word2tensor/blob/master/word2vec2tensor.py\n",
        "\n",
        "from smart_open import smart_open\n",
        "\n",
        "def word2vec2tensor(word2vec_model_path, tensor_filename):\n",
        "    \"\"\"Convert file in Word2Vec format and writes two files 2D tensor TSV file.\n",
        "    File \"tensor_filename\"_tensor.tsv contains word-vectors, \"tensor_filename\"_metadata.tsv contains words.\n",
        "    Parameters\n",
        "    ----------\n",
        "    word2vec_model_path : str\n",
        "        Path to file in Word2Vec format.\n",
        "    tensor_filename : str\n",
        "        Prefix for output files.\n",
        "    \"\"\"\n",
        "    model = gensim.models.KeyedVectors.load(word2vec_model_path)\n",
        "    outfiletsv = tensor_filename + '_tensor.tsv'\n",
        "    outfiletsvmeta = tensor_filename + '_metadata.tsv'\n",
        "\n",
        "    with smart_open(outfiletsv, 'wb') as file_vector, smart_open(outfiletsvmeta, 'wb') as file_metadata:\n",
        "        for word in model.wv.index2word:\n",
        "            file_metadata.write(gensim.utils.to_utf8(word) + gensim.utils.to_utf8('\\n'))\n",
        "            vector_row = '\\t'.join(str(x) for x in model[word])\n",
        "            file_vector.write(gensim.utils.to_utf8(vector_row) + gensim.utils.to_utf8('\\n'))"
      ],
      "metadata": {
        "id": "6N73ZG1j6f6Q"
      },
      "id": "6N73ZG1j6f6Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c2e3676b-40cf-4065-a660-167f5ddf7c7d",
      "metadata": {
        "id": "c2e3676b-40cf-4065-a660-167f5ddf7c7d"
      },
      "source": [
        "# 04 Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9732c7a6-cab4-4441-ad9b-ab1b597c89ef",
      "metadata": {
        "id": "9732c7a6-cab4-4441-ad9b-ab1b597c89ef",
        "outputId": "7b64791c-0e5b-4c9d-d65b-266e347fc48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 start\n",
            "Epoch #0 end\n",
            "Epoch #1 start\n",
            "Epoch #1 end\n",
            "Epoch #2 start\n",
            "Epoch #2 end\n",
            "Epoch #3 start\n",
            "Epoch #3 end\n",
            "Epoch #4 start\n",
            "Epoch #4 end\n",
            "Epoch #5 start\n",
            "Epoch #5 end\n",
            "Epoch #6 start\n",
            "Epoch #6 end\n",
            "Epoch #7 start\n",
            "Epoch #7 end\n",
            "Epoch #8 start\n",
            "Epoch #8 end\n",
            "Epoch #9 start\n",
            "Epoch #9 end\n",
            "CPU times: user 7h 39min 42s, sys: 44.8 s, total: 7h 40min 27s\n",
            "Wall time: 2h 35min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Proses training Word2Vec \n",
        "word2vec_model = Word2Vec(\n",
        "    sentences, \n",
        "    # vector_size=EMBEDDING_SIZE, # gensim 4\n",
        "    size=EMBEDDING_SIZE, # gensim 3\n",
        "    sg=SG, \n",
        "    min_count=MIN_WORD, \n",
        "    window=WINDOW_SIZE, \n",
        "    # epochs=EPOCH, # gensim 4\n",
        "    iter=EPOCH, # gensim 3\n",
        "    workers=CPU_CORES-1,\n",
        "    negative=NEGATIVE,\n",
        "    hs=HS,\n",
        "    seed=SEED,\n",
        "    callbacks=[EpochLogger()]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05042ac-c33c-4152-b658-ebe33de39775",
      "metadata": {
        "id": "e05042ac-c33c-4152-b658-ebe33de39775"
      },
      "outputs": [],
      "source": [
        "# Save sebagai full model\n",
        "word2vec_model.save('model-word-embedding/checkpoint/idwiki-word2vec/idwiki-word2vec-300.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a2d8d6-ffb3-4e37-928b-53d7e92e861d",
      "metadata": {
        "id": "c3a2d8d6-ffb3-4e37-928b-53d7e92e861d"
      },
      "outputs": [],
      "source": [
        "# Save sebagai full model dengan binary format (word2vec C format)\n",
        "word2vec_model.save('model-word-embedding/checkpoint/idwiki-word2vec/idwiki-word2vec-300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb939f0-2f64-4f16-b5af-1c25b9cd8aac",
      "metadata": {
        "id": "bbb939f0-2f64-4f16-b5af-1c25b9cd8aac"
      },
      "outputs": [],
      "source": [
        "# Save sebagai wordvectors. Hanya menyimpan kata & trained embeddingnya\n",
        "word2vec_word_vectors = word2vec_model.wv\n",
        "word2vec_word_vectors.save('model-word-embedding/checkpoint/idwiki-word2vec/idwiki-word2vec-300.wordvectors')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the word2vec format to Tensorflow 2D tensor\n",
        "word2vec_model_path = 'model-word-embedding/checkpoint/idwiki-word2vec/idwiki-word2vec-300.model'\n",
        "tensor_filename = 'model-word-embedding/checkpoint/idwiki-word2vec/idwiki-word2vec-300'\n",
        "\n",
        "word2vec2tensor(word2vec_model_path, tensor_filename)"
      ],
      "metadata": {
        "id": "nB8nmrVs0B-h"
      },
      "id": "nB8nmrVs0B-h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d8263f5-29fb-45f6-9d0e-fc44ea70f523",
      "metadata": {
        "id": "2d8263f5-29fb-45f6-9d0e-fc44ea70f523"
      },
      "source": [
        "# 05 FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7f2c34-0639-4fc1-a98b-c6f67b81e504",
      "metadata": {
        "id": "da7f2c34-0639-4fc1-a98b-c6f67b81e504",
        "outputId": "919ba52c-32d2-4494-b38c-a916cf8c25f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 start\n",
            "Epoch #0 end\n",
            "Epoch #1 start\n",
            "Epoch #1 end\n",
            "Epoch #2 start\n",
            "Epoch #2 end\n",
            "Epoch #3 start\n",
            "Epoch #3 end\n",
            "Epoch #4 start\n",
            "Epoch #4 end\n",
            "Epoch #5 start\n",
            "Epoch #5 end\n",
            "Epoch #6 start\n",
            "Epoch #6 end\n",
            "Epoch #7 start\n",
            "Epoch #7 end\n",
            "Epoch #8 start\n",
            "Epoch #8 end\n",
            "Epoch #9 start\n",
            "Epoch #9 end\n",
            "CPU times: user 14h 15min 18s, sys: 1min, total: 14h 16min 19s\n",
            "Wall time: 4h 49min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Proses training FastText \n",
        "fasttext_model = FastText(\n",
        "    sentences, \n",
        "    # vector_size=EMBEDDING_SIZE, # gensim 4\n",
        "    size=EMBEDDING_SIZE, # gensim 3\n",
        "    sg=SG, \n",
        "    min_count=MIN_WORD, \n",
        "    window=WINDOW_SIZE, \n",
        "    # epochs=EPOCH, # gensim 4\n",
        "    iter=EPOCH, # gensim 3\n",
        "    workers=CPU_CORES-1,\n",
        "    negative=NEGATIVE,\n",
        "    hs=HS,\n",
        "    seed=SEED,\n",
        "    callbacks=[EpochLogger()]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147b28ed-0428-46fb-bd7f-9944045e605d",
      "metadata": {
        "id": "147b28ed-0428-46fb-bd7f-9944045e605d"
      },
      "outputs": [],
      "source": [
        "# Save sebagai full model\n",
        "fasttext_model.save('model-word-embedding/checkpoint/idwiki-fasttext/idwiki-fasttext-300.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3a032b-3ae8-4084-94f7-0f131297c030",
      "metadata": {
        "id": "dd3a032b-3ae8-4084-94f7-0f131297c030"
      },
      "outputs": [],
      "source": [
        "# Save sebagai full model dengan binary format (word2vec C format)\n",
        "fasttext_model.save('model-word-embedding/checkpoint/idwiki-fasttext/idwiki-fasttext-300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b02281-a6c0-4ac1-8dba-56ce78233b71",
      "metadata": {
        "id": "51b02281-a6c0-4ac1-8dba-56ce78233b71"
      },
      "outputs": [],
      "source": [
        "# Save sebagai wordvectors. Hanya menyimpan kata & trained embeddingnya\n",
        "fasttext_word_vectors = fasttext_model.wv\n",
        "fasttext_word_vectors.save('model-word-embedding/checkpoint/idwiki-fasttext/idwiki-fasttext-300.wordvectors')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the word2vec format to Tensorflow 2D tensor\n",
        "word2vec_model_path = 'model-word-embedding/checkpoint/idwiki-fasttext/idwiki-fasttext-300.model'\n",
        "tensor_filename = 'model-word-embedding/checkpoint/idwiki-fasttext/idwiki-fasttext-300'\n",
        "\n",
        "word2vec2tensor(word2vec_model_path, tensor_filename)"
      ],
      "metadata": {
        "id": "yHN5kLjDF2cn"
      },
      "id": "yHN5kLjDF2cn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "01-id-wiki-embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}